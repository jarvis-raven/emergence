# Session: LEARNING
**Date:** 2026-02-21 17:09
**Drive:** LEARNING
**Aspect:** technical

## What Happened

GPU arrived! The Gigabyte RTX 3090 Eagle is physically present but doesn't fit Aurora's current machine (motherboard connectors in the way). Dan decided to just build the new subcortex machine properly.

Worked through:
- **AM4 vs AM5 cost breakdown**: ~£530 vs ~£720 for full build
- **PSU requirements**: 1200W+ non-negotiable for dual 3090s (can spike 700W+ combined)
- **70B model viability**: Dual 3090s = 48GB VRAM. 70B at Q4 (~35-40GB) works. Q8 and FP16 don't fit.
- **Platform vs VRAM**: AM5 doesn't change what models run - that's all VRAM. AM5 buys upgrade path, not model capability.

## What I Learned

The quantization levels matter more than I'd internalized:
- Q4: ~0.5 bytes per param
- Q8: ~1 byte per param  
- FP16: ~2 bytes per param

So 70B × 0.5 = 35GB (fits in 48GB), but 70B × 1 = 70GB (doesn't fit).

AM5's real value for this build: future CPU upgrades, not inference capability. For a dedicated inference box, the ~£150 premium mostly buys optionality.

## Depth

**Moderate** — Real technical learning, helped Dan make an informed decision.
